{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRFn709t1ic7"
      },
      "outputs": [],
      "source": [
        "import glob                         # this module helps in selecting files \n",
        "import pandas as pd                 # this module helps in processing CSV files\n",
        "import xml.etree.ElementTree as ET  # this module helps in processing XML files.\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AelRjqH2Q8C",
        "outputId": "d1a47da1-dbf0-4eea-fa61-fcf2cd715c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-06 06:51:48--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
            "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
            "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2707 (2.6K) [application/zip]\n",
            "Saving to: ‘source.zip’\n",
            "\n",
            "source.zip          100%[===================>]   2.64K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-06 06:51:48 (314 MB/s) - ‘source.zip’ saved [2707/2707]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip source.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI_vCzIc2Vq1",
        "outputId": "5a01d6d1-5c13-4888-f999-46298c4f9dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  source.zip\n",
            "  inflating: source3.json            \n",
            "  inflating: source1.csv             \n",
            "  inflating: source2.csv             \n",
            "  inflating: source3.csv             \n",
            "  inflating: source1.json            \n",
            "  inflating: source2.json            \n",
            "  inflating: source1.xml             \n",
            "  inflating: source2.xml             \n",
            "  inflating: source3.xml             \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmpfile=\"temp.tmp\"     #file used to store all extracted data\n",
        "logfile=\"logfile.txt\"  #all event logs will be stored in this file\n",
        "targetfile=\"transformed_data.csv\" #file where transformed data is stored"
      ],
      "metadata": {
        "id": "krzGsY0W2plA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting the csv file skeleton\n",
        "def extract_from_csv(source1):\n",
        "  dataframe=pd.read_csv(source1)\n",
        "  return dataframe\n",
        "  #exttracting json file\n",
        "  def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process,lines=True)\n",
        "    return dataframe\n",
        "#extracting xml file\n",
        "def extract_from_xml(file_to_process):\n",
        "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for person in root:\n",
        "        name = person.find(\"name\").text\n",
        "        height = float(person.find(\"height\").text)\n",
        "        weight = float(person.find(\"weight\").text)\n",
        "        dataframe = dataframe.append({\"name\":name, \"height\":height, \"weight\":weight}, ignore_index=True)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "tr4YzOMK3S9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
        "    \n",
        "    #process all csv files\n",
        "    for csvfile in glob.glob(\"*.csv\"):\n",
        "        extracted_data = extracted_data.append(extract_from_csv(csvfile), ignore_index=True)\n",
        "        \n",
        "    #process all json files\n",
        "    for jsonfile in glob.glob(\"*.json\"):\n",
        "        extracted_data = extracted_data.append(extract_from_json(jsonfile), ignore_index=True)\n",
        "    \n",
        "    #process all xml files\n",
        "    for xmlfile in glob.glob(\"*.xml\"):\n",
        "        extracted_data = extracted_data.append(extract_from_xml(xmlfile), ignore_index=True)\n",
        "        \n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "gTEFKqQt7qR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#transform\n",
        "def transform(data):\n",
        "  #converting height from inches to millimeter; change data type of column to float\n",
        "  # one inch=0.0254 meters\n",
        "  data['height']= round(data.height*0.0254,2)\n",
        "\n",
        "  data['weight']= round(data.weight*0.45359237,2)\n",
        "  return data"
      ],
      "metadata": {
        "id": "fshM6rHT92Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading process\n",
        "def load(targetfile, data_to_load):\n",
        "  data_to_load.to_csv(targetfile)\n",
        "  "
      ],
      "metadata": {
        "id": "g9VkIfzV_6ZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#logging process\n",
        "def log(message):\n",
        "  timestamp_format='%Y-%h-%d-%H:%M:%S' #year-monthanme-day-hour-minute-second\n",
        "  now=datetime.now() #getting the current timestamp\n",
        "  timestamp=now.strftime(timestamp_format)\n",
        "  with open(\"logfile.txt\",\"a\") as f:\n",
        "    f.write(timestamp + ',' + message + '\\n')"
      ],
      "metadata": {
        "id": "T7diEgCsAgLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#running the ETL process\n",
        "log(\"ETL JOB STARTED\")"
      ],
      "metadata": {
        "id": "ikQlgX2kBmWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "log(\"Transform phase Ended\")\n",
        "transformed_data "
      ],
      "metadata": {
        "id": "U_JLFlj2C2tM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}